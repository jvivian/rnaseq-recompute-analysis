{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Dataset is a Sample From?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_dir = '/mnt/rna-seq-analysis/rna-seq-analysis/data/tissue-pairs'\n",
    "tissues = os.listdir(exp_dir)\n",
    "tsv = 'combined-gtex-tcga-counts-protein-coding.tsv'\n",
    "exp_df = pd.concat([pd.read_csv(os.path.join(exp_dir, t, tsv), sep='\\t', index_col=0) for t in tissues], axis=1)\n",
    "# Remove dupes\n",
    "exp_df = exp_df.T.groupby(level=0).first().T\n",
    "# Subset by normal / tumor samples\n",
    "samples = [x for x in exp_df.columns if x.startswith('GTEX') or (x.endswith('01') or x.endswith('11'))]\n",
    "exp_df = exp_df[samples]\n",
    "# Transpose so genes (features) are columns\n",
    "exp_df = exp_df.T\n",
    "# Scale Dataframe\n",
    "scale_df = scale(exp_df)\n",
    "\n",
    "# Get Y\n",
    "y = []\n",
    "for x in exp_df.index:\n",
    "    if x.startswith('GTEX'):\n",
    "        y.append('g')\n",
    "    elif x.endswith('-11'):\n",
    "        y.append('n')\n",
    "    else:\n",
    "        y.append('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('classify', LinearSVC())\n",
    "])\n",
    "\n",
    "N_FEATURES_OPTIONS = [10, 100, 500, 1000, 5000]\n",
    "C_OPTIONS = [1, 10, 100, 1000]\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "]\n",
    "reducer_labels = ['PCA', 'NMF', 'KBest(chi2)']\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=3, n_jobs=-1, param_grid=param_grid, verbose=1)\n",
    "grid.fit(scale_df, y)\n",
    "\n",
    "\"\"\"\n",
    "Printing\n",
    "\"\"\"\n",
    "print \"Performing grid search...\"\n",
    "print \"pipeline:\", [name for name, _ in pipe.steps]\n",
    "print \"parameters:\"\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid.fit(scale_df, y)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "print\n",
    "\n",
    "print \"Best score: %0.3f\" % grid.best_score_\n",
    "print \"Best parameters set:\"\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print \"\\t%s: %r\" % (param_name, best_parameters[param_name])\n",
    "\n",
    "\"\"\"\n",
    "Plot\n",
    "\"\"\"\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "# scores are in the order of param_grid iteration, which is alphabetical\n",
    "mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# select score for best C\n",
    "mean_scores = mean_scores.max(axis=0)\n",
    "bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *\n",
    "               (len(reducer_labels) + 1) + .5)\n",
    "plt.figure()\n",
    "COLORS = 'bgrcmyk'\n",
    "for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n",
    "    plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])\n",
    "\n",
    "plt.title(\"Comparing feature reduction techniques\")\n",
    "plt.xlabel('Reduced number of features')\n",
    "plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n",
    "plt.ylabel('Tumorous classification accuracy')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('dataset_features.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
